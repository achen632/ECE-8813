import json
# The json_repair package is one option to pull json from the LLM responses.
# import json_repair
from helper import ask_agent, load_input_data

def task_1_solution(sample_number: int) -> int:
    """Takes in the static and dynamic analysis data and returns the address
    of the first branch instruction responsible for terminating early and hiding
    the malware's malicious behaviors.
    """
    static_data, api_calls = load_input_data(sample_number)

    # TODO: Implement the logic to analyze static_data and dynamic_data
    # and find the address of the first branch instruction that causes early 
    # termination.
    # N.B. You can use the ask_agent function to get help from the AI agent.
    # Keep in mind that there is a token limit, so you may need to reduce the 
    # amount of data you include in a prompt.
    # response = ask_agent("Your prompt here")

    branch_address = 0
    assert isinstance(branch_address, int), f"The answer must be an integer representing the address, the actual type is: {type(branch_address)}"
    return branch_address



def task_2_solution(sample_number: int) -> str:
    """Takes in the static and dynamic analysis data and returns the address
    of the first branch instruction responsible for terminating early and hiding
    the malware's malicious behaviors.
    """

    static_data, api_calls = load_input_data(sample_number)

    # TODO: Implement the logic to analyze static_data and dynamic_data
    # and write a python script that sets up the sandbox environment to 
    # ensure the malware fully executes.
    # N.B. You can use the ask_agent function to get help from the AI agent.
    # Keep in mind that there is a token limit, so you may need to reduce the 
    # amount of data you include in a prompt.
    # response = ask_agent("Your prompt here")

    python_script = ""
    assert isinstance(python_script, str), "The answer must be a python script."
    return python_script

